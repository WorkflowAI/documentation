# Pricing

WorkflowAI Cloud is a pay-as-you-go infrastructure, similar to Amazon Web Services. There is no fixed cost, minimum spend, or annual commitment. You don't need to talk to sales to get started.

## Costs

WorkflowAI Cloud charges only for:
- the tokens generated by your AI agents (per token generated)
- the tools used by your AI agents (per tool used)

We **don't** charge by:
- GB of data stored
- number of AI agents
- number of members in your organization
- bandwidth or CPU usage

## Price match guarantee

For any AI provider, we offer a price-match guarantee: WorkflowAI Cloud **charges the same per token price** as the AI provider you're using. Currently, we support models from OpenAI, Anthropic, Google, Mistral, DeepSeek, and LLAMA (provided by [FireworksAI](https://fireworks.ai/)).

If you have credits with Amazon, Google, or Azure, you can also continue to use them via WorkflowAI Cloud, [by providing your own API keys](/docs/features/deployments.md#using-your-own-ai-providers-api).

## What is WorkflowAI Cloud business model?

We are making our margin by buying LLMs tokens in bulk, with a discount, and then reselling them to you at public price.

Thinking from first principles, the cost of inference is mostly GPU and electricity, not tokens. When you buy tokens from a LLM provider, effectively you are paying for the electricity and GPU cost. But renting a GPU makes only sense if you can utilize the GPU at maximum capacity, all the time. 